[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Getting Started with OpenAI API: A Beginner‚Äôs Guide",
    "section": "",
    "text": "Preface\nWelcome to ‚ÄúGetting Started with OpenAI API: A Beginner‚Äôs Guide,‚Äù an ebook designed especially for beginners who wants to start build AI application using the powerful APIs of OpenAI. This ebook is intended to provide a clear and comprehensive guide for beginners who want to start using the OpenAI models with Python.\nHere‚Äôs a quick overview of the chapters you‚Äôll find in this ebook:\n\nChapter 1: Using OpenAI models in Python\nWe will start by installing the necessary Python libraries and creating an OpenAI API key. Then, we will show you how to perform some basic tasks with OpenAI models, such as text summarization and output in a given format.\n\n\nChapter 2: Structure and output of OpenAI‚Äôs ChatCompletion\nWe will explain how the openai.ChatCompletion model works and what kind of outputs it can generate. We will also show you how to use the model parameters and options to customize the outputs.\n\n\nChapter 3: Structure of conversation or messages in ChatCompletion\nWe will discuss how to structure the conversation or messages that are used as inputs for the openai.ChatCompletion model. We will also provide some tips and best practices for creating engaging and coherent conversations.\n\n\nChapter 4: Create a solution using Streamlit which will chat with the PDF document in your directory\nWe will demonstrate how to use Streamlit, a Python library for creating interactive web applications, to build a solution that will allow you to chat with any PDF document in your directory using the openai.ChatCompletion model.\nThis ebook is suitable for anyone who has a basic knowledge of Python and wants to learn how to use the OpenAI models effectively. This ebook does not require any prior experience with the OpenAI models or the OpenAI API. The ebook provides many examples and code snippets that can be easily adapted and modified for different purposes and scenarios.\nBy reading this ebook, you will gain a solid understanding of the OpenAI models and how to use them with Python. You will also learn how to avoid common mistakes and pitfalls.\nI hope that you will find this ebook useful and informative, and that it will inspire you to explore and experiment with the OpenAI models and the API. I also hope that you will share your feedback and suggestions with me, so that I can improve and update this ebook in the future.\nThank you for choosing this ebook and happy learning!"
  },
  {
    "objectID": "1_Chapter.html#getting-started",
    "href": "1_Chapter.html#getting-started",
    "title": "1 Getting started",
    "section": "Getting started",
    "text": "Getting started\nTo get started with OpenAI models in Python, you will need to install the openai library.\n!pip install openai\nAfter you have installed, you will also need to create an OpenAI API key by signing up for opena an OpenAI account. You can use this link to sign up for OpenAI account. Once you sign up you will get a free credit of $5 which you need to consume in three months. You can create secret API key by going to API key page on OpenAI platform.\nOnce you have installed the necessary libraries and created an API key, you have to load the libraries and OpenAI key. You can either hardcode the API Key or you can use an environment variable to store this.\nimport openai\nimport os\n\n# A sample value for illustration which will not work :)\n# openai.api_key  = \"&lt;put your key here&gt;\" \n\nopenai.api_key  = os.getenv('OPENAI_API_KEY')\nAfter you have Python configured and set up API key, the next step is to send request to OpenAI model using API. I have a created a helper function for simplicity.\ndef get_completion(prompt ):\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    response = openai.ChatCompletion.create(\n        model=\"gpt-3.5-turbo\",\n        messages=messages,\n        temperature=0.1, # this is the degree of randomness of the model's output\n    )\n    return response.choices[0].message[\"content\"]\nThis function takes a prompt (text) as input and return the response from OpenAI as output. You can test this function using any simple prompt.\nprompt = \"When Indian constitution was adopted?\"\n\noutput = get_completion(prompt)\nprint(output)\n\n\n\n\n\n\nOutput\n\n\n\nThe Indian constitution was adopted on November 26, 1949.\n\n\nWhen you execute this, API calls goes to OpenAI with your query and OpenAI returns the output as text."
  },
  {
    "objectID": "1_Chapter.html#example-1-text-summarization",
    "href": "1_Chapter.html#example-1-text-summarization",
    "title": "1 Getting started",
    "section": "Example 1 Text summarization",
    "text": "Example 1 Text summarization\n\n\nShow text\ntext = \"\"\"\nConsuming a healthy diet throughout the life-course helps to prevent malnutrition in all its forms as well as a range of noncommunicable diseases (NCDs) and conditions. However, increased production of processed foods, rapid urbanization and changing lifestyles have led to a shift in dietary patterns. People are now consuming more foods high in energy, fats, free sugars and salt/sodium, and many people do not eat enough fruit, vegetables and other dietary fibre such as whole grains.\n\nThe exact make-up of a diversified, balanced and healthy diet will vary depending on individual characteristics (e.g. age, gender, lifestyle and degree of physical activity), cultural context, locally available foods and dietary customs. However, the basic principles of what constitutes a healthy diet remain the same.\n\nFor adults\nA healthy diet includes the following:\n\nFruit, vegetables, legumes (e.g. lentils and beans), nuts and whole grains (e.g. unprocessed maize, millet, oats, wheat and brown rice).\nAt least 400 g (i.e. five portions) of fruit and vegetables per day (2), excluding potatoes, sweet potatoes, cassava and other starchy roots.\nLess than 10% of total energy intake from free sugars (2, 7), which is equivalent to 50 g (or about 12 level teaspoons) for a person of healthy body weight consuming about 2000 calories per day, but ideally is less than 5% of total energy intake for additional health benefits (7). Free sugars are all sugars added to foods or drinks by the manufacturer, cook or consumer, as well as sugars naturally present in honey, syrups, fruit juices and fruit juice concentrates.\nLess than 30% of total energy intake from fats (1, 2, 3). Unsaturated fats (found in fish, avocado and nuts, and in sunflower, soybean, canola and olive oils) are preferable to saturated fats (found in fatty meat, butter, palm and coconut oil, cream, cheese, ghee and lard) and trans-fats of all kinds, including both industrially-produced trans-fats (found in baked and fried foods, and pre-packaged snacks and foods, such as frozen pizza, pies, cookies, biscuits, wafers, and cooking oils and spreads) and ruminant trans-fats (found in meat and dairy foods from ruminant animals, such as cows, sheep, goats and camels). It is suggested that the intake of saturated fats be reduced to less than 10% of total energy intake and trans-fats to less than 1% of total energy intake (5). In particular, industrially-produced trans-fats are not part of a healthy diet and should be avoided (4, 6).\nLess than 5  g of salt (equivalent to about one teaspoon) per day (8).  Salt should be iodized.\nFor infants and young children\nIn the first 2 years of a child‚Äôs life, optimal nutrition fosters healthy growth and improves cognitive development. It also reduces the risk of becoming overweight or obese and developing NCDs later in life.\n\nAdvice on a healthy diet for infants and children is similar to that for adults, but the following elements are also important:\n\nInfants should be breastfed exclusively during the first 6 months of life.\nInfants should be breastfed continuously until 2 years of age and beyond.\nFrom 6 months of age, breast milk should be complemented with a variety of adequate, safe and nutrient-dense foods. Salt and sugars should not be added to complementary foods.\nPractical advice on maintaining a healthy diet\nFruit and vegetables\nEating at least 400 g, or five portions, of fruit and vegetables per day reduces the risk of NCDs (2) and helps to ensure an adequate daily intake of dietary fibre.\n\nFruit and vegetable intake can be improved by:\n\nalways including vegetables in meals;\neating fresh fruit and raw vegetables as snacks;\neating fresh fruit and vegetables that are in season; and\neating a variety of fruit and vegetables.\nFats\nReducing the amount of total fat intake to less than 30% of total energy intake helps to prevent unhealthy weight gain in the adult population (1, 2, 3). Also, the risk of developing NCDs is lowered by:\n\nreducing saturated fats to less than 10% of total energy intake;\nreducing trans-fats to less than 1% of total energy intake; and\nreplacing both saturated fats and trans-fats with unsaturated fats (2, 3) ‚Äì in particular, with polyunsaturated fats.\nFat intake, especially saturated fat and industrially-produced trans-fat intake, can be reduced by:\n\nsteaming or boiling instead of frying when cooking;\nreplacing butter, lard and ghee with oils rich in polyunsaturated fats, such as soybean, canola (rapeseed), corn, safflower and sunflower oils;\neating reduced-fat dairy foods and lean meats, or trimming visible fat from meat; and\nlimiting the consumption of baked and fried foods, and pre-packaged snacks and foods (e.g. doughnuts, cakes, pies, cookies, biscuits and wafers) that contain industrially-produced trans-fats.\nSalt, sodium and potassium\nMost people consume too much sodium through salt (corresponding to consuming an average of 9‚Äì12 g of salt per day) and not enough potassium (less than 3.5 g). High sodium intake and insufficient potassium intake contribute to high blood pressure, which in turn increases the risk of heart disease and stroke (8, 11).\n\nReducing salt intake to the recommended level of less than 5 g per day could prevent 1.7 million deaths each year (12).\n\nPeople are often unaware of the amount of salt they consume. In many countries, most salt  comes from processed foods (e.g. ready meals; processed meats such as bacon, ham and salami; cheese; and salty snacks) or from foods consumed frequently in large amounts (e.g. bread). Salt is also added to foods during cooking (e.g. bouillon, stock cubes, soy sauce and fish sauce) or at the point of consumption (e.g. table salt).\n\nSalt intake can be reduced by:\n\nlimiting the amount of salt and high-sodium condiments (e.g. soy sauce, fish sauce and bouillon) when cooking and preparing foods;\nnot having salt or high-sodium sauces on the table;\nlimiting the consumption of salty snacks; and\nchoosing products with lower sodium content.\nSome food manufacturers are reformulating recipes to reduce the sodium content of their products, and people should be encouraged to check nutrition labels to see how much sodium is in a product before purchasing or consuming it.\n\nPotassium can mitigate the negative effects of elevated sodium consumption on blood pressure. Intake of potassium can be increased by consuming fresh fruit and vegetables.\n\nSugars\nIn both adults and children, the intake of free sugars should be reduced to less than 10% of total energy intake (2, 7).  A reduction to less than 5% of total energy intake would provide additional health benefits (7).\n\nConsuming free sugars increases the risk of dental caries (tooth decay). Excess calories from foods and drinks high in free sugars also contribute to unhealthy weight gain, which can lead to overweight and obesity. Recent evidence also shows that free sugars influence blood pressure and serum lipids, and suggests that a reduction in free sugars intake reduces risk factors for cardiovascular diseases (13).\n\nSugars intake can be reduced by:\n\nlimiting the consumption of foods and drinks containing high amounts of sugars, such as sugary snacks, candies and sugar-sweetened beverages (i.e. all types of beverages containing free sugars ‚Äì these include carbonated or non‚Äêcarbonated soft drinks, fruit or vegetable juices and drinks, liquid and powder concentrates, flavoured water, energy and sports drinks, ready‚Äêto‚Äêdrink tea, ready‚Äêto‚Äêdrink coffee and flavoured milk drinks); and\neating fresh fruit and raw vegetables as snacks instead of sugary snacks.\n\"\"\"\n\n\nSome text\nprompt = f\"\"\"\nSummarize the text delimited by triple backticks \\ \ninto one paragraph.\n```{text}```\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\nConsuming a healthy diet is important for preventing malnutrition and noncommunicable diseases. However, dietary patterns have shifted due to increased production of processed foods and changing lifestyles. People are now consuming more high-energy, fatty, sugary, and salty foods, while not eating enough fruits, vegetables, and whole grains. The composition of a healthy diet varies based on individual characteristics, cultural context, and locally available foods. For adults, a healthy diet includes fruits, vegetables, legumes, nuts, and whole grains. It should also limit the intake of sugars and fats, particularly saturated and trans fats. Salt intake should be limited to less than 5g per day. For infants and young children, breastfeeding is recommended for the first 6 months and should be continued until 2 years of age. From 6 months, breast milk should be supplemented with nutrient-dense foods without added salt or sugars. Practical advice for maintaining a healthy diet includes eating a variety of fruits and vegetables, reducing fat intake, and limiting salt and sugar consumption."
  },
  {
    "objectID": "1_Chapter.html#example-2---extracting-info-from-text-in-json-format",
    "href": "1_Chapter.html#example-2---extracting-info-from-text-in-json-format",
    "title": "1 Getting started",
    "section": "Example 2 - Extracting info from text in JSON format",
    "text": "Example 2 - Extracting info from text in JSON format\nHere is another example where, we will see how to extract meaningful information from text in a json format.\nThe text is copied from from the press release of a motor company which is in the pdf format.\n\n\nShow text\ntext_car_sales = \"\"\"\nTata Motors Consolidated:\nTML continued its strong performance in Q1 FY24 with Revenues at ‚Çπ102.2K Cr (up 42% yoy), EBITDA at ‚Çπ14.7K Cr (up\n177% yoy) and EBIT of ‚Çπ8.3KCr (higher by ‚Çπ8.8KCr), all showing a sharp improvement driven by JLR and CV businesses\nwhilst the PV business was steady. JLR revenues improved by 57% to ¬£6.9b on strong wholesales and improved mix\nresulting in EBIT margins of 8.6% (+1,300bps). CV volumes were lower by 15% over prior year due to transition to BS6\nPhase 2. However, the EBIT margins improved to 6.5% (+370bps) benefiting from the demand-pull strategy and richer mix.\nPV business was steady with 11.1% revenue growth and EBIT of 1.0% (+10bps). Overall PBT (bei) improved by ‚Çπ10.3KCr to\n‚Çπ5.3KCr and Net Profit was ‚Çπ3.3KCr.\nLooking Ahead:\nWe remain optimistic on the demand situation despite near term uncertainties and expect a moderate inflationary\nenvironment to continue in the near term. We aim to deliver a strong performance in the rest of the year too, thanks to\na healthy order book coupled with low-break-even in JLR, a steady improvement in demand whilst we continue to drive\nour demand-pull strategy in CV, a set of exciting launches ahead of the festive season in PV and continued aggression in\nEVs.\nPB Balaji, Group Chief Financial Officer, Tata Motors said:\n‚ÄúFY24 has begun on the right note with all automotive verticals delivering strong performances. The distinct strategy\nemployed by each business is now delivering consistent results and making them structurally stronger. We remain\nconfident of sustaining this momentum in the rest of the year and achieve our stated goals.‚Äù\nQ\n1 FY2\n4\nConsolidated\n(‚Çπ Cr Ind AS)\nJaguar Land Rover\n(¬£m, IFRS)\nTata Commercial\nVehicles (‚ÇπCr, Ind AS)\nTata Passenger\nVehicles (‚ÇπCr, Ind AS)\nFY24 Vs. PY FY24 Vs. PY FY24 Vs. PY FY24 Vs. PY\nRevenue 102,236 42.1 % 6,903 57.0 % 16,991 4.4% 12,839 11.1 %\nEBITDA (%) 14.4 700 bps 16.3 960 bps 9.4 390 bps 5.3 (80) bps\nEBIT (%) 8.1 880 bps 8.6 1,300 bps 6.5 370 bps 1.0 10 bps\nPBT (bei) 5,330 ‚Çπ10,292crs 435 ¬£959m 937 ‚Çπ635 crs 186 ‚Çπ172 crs\nTata Motors Group Results Q1 FY24 July 25, 2023\nPage 2 of 5\nHighlights\n‚Ä¢ Revenues in Q1 FY24 of ¬£6.9 billion, up 57% (y-o-y).\n‚Ä¢ PBT (bei) in Q1 FY24 was ¬£435 million, up ¬£67 million from Q4 FY23 and up nearly ¬£1 billion from Q1 FY23.\n‚Ä¢ EBIT margin in the quarter was 8.6%, up from 6.5% in Q4 FY23.\n‚Ä¢ The higher profitability year-on-year reflects favourable volume, mix, pricing and foreign exchange revaluation\noffset partially by higher inflation and supplier claims.\n‚Ä¢ FCF of ¬£451 million, the highest JLR Q1 cash flow on record; cumulative FCF over the last three quarters is ¬£1.8\nbillion.\n‚Ä¢ Cash on hand increased to ¬£4 billion and net debt reduced to ¬£2.5 billion at June 30, 2023.\n‚Ä¢ Order book strong at 185k units with Range Rover, Range Rover Sport and Defender representing 76% of the order\nbook.\n‚Ä¢ Adrian Mardell and Richard Molyneux confirmed as Chief Executive Officer and Chief Financial Officer respectively.\n‚Ä¢ Tata‚Äôs newly announced ¬£4bn UK gigafactory will provide JLR with stable and secure supply of battery cells to\nelectrify JLR‚Äôs next generation modern luxury vehicles.\nReimagine Transformation\n‚Ä¢ Our first Reimagined modern luxury electric vehicle to go on sale will be Range Rover BEV, available for pre-order\nlater this year and on sale in 2024.\n‚Ä¢ Range Rover Sport named the 2023 Auto Express Large Premium SUV of the year 2023.\n‚Ä¢ JLR‚Äôs Jaguar and Land Rover (Range Rover, Defender, Discovery) brands placed top of a J.D. Power US ‚ÄòAutomotive\nPerformance, Execution and Layout (APEAL)‚Äô based on client perceptions of design, performance, safety, comfort\nand quality.\n‚Ä¢ Model year refreshes of Discovery Sport and Range Rover Evoque with significant interior upgrades. Outbound\nEdition of Defender 130 launched.\n‚Ä¢ Limited edition New Range Rover Sport SV EDITION ONE, with pricing ranging from ¬£168,800 to more than\n¬£190,000 in the UK, was fully reserved ahead of its launch in May, following exclusive Range Rover House preview\nevents.\n‚Ä¢ Digital transformation continues with Tata Technologies to support Enterprise Risk Management (ERM) across the\nbusiness and with Everstream to use AI to monitor our global supply chains.\n\n\"\"\"\n\n\nNow, the code to call this function, we‚Äôll use\nprompt = f\"\"\"\nExtract the numbers with their key from the below text delimited by triple backticks.\nUse JSON format to show your result.\n\n```{text_car_sales}```\n\"\"\"\nresponse = get_completion(prompt)\n\nThe OpenAI model has returned the output in a json string format. We can play with this string and create a json object . In the last we can create a data frame using the json object.\n\nimport json\nparse_response = json.loads(response)\n\n\nimport pandas as pd\npd.DataFrame(parse_response).T\n\n\n\n\n\n\n\n\nTata Motors Consolidated\nJaguar Land Rover\nTata Commercial Vehicles\nTata Passenger Vehicles\n\n\n\n\nRevenues\n‚Çπ102.2K Cr\n¬£6.9b\n‚Çπ16,991 Cr\n‚Çπ12,839 Cr\n\n\nEBITDA\n‚Çπ14.7K Cr\n16.3\n9.4\n5.3\n\n\nEBIT\n‚Çπ8.3KCr\n8.6\n6.5\n1.0\n\n\nPBT (bei)\n‚Çπ5.3KCr\n435\n937\n186\n\n\n\n\n\n\n\n\nSummary\nIn this chapter, we saw how to start working with OpenAI GPT models using API. In the next chapter we‚Äôll see how to work with system prompt."
  },
  {
    "objectID": "2_chapter.html#structure-of-helper-function",
    "href": "2_chapter.html#structure-of-helper-function",
    "title": "2 Structure of API function",
    "section": "Structure of helper function",
    "text": "Structure of helper function\nIn the last chapter, we have used a pre-defined helper function to send request to OpenAI and get response.\n\n\n\nWarning: package 'gt' was built under R version 4.3.1\n\n\n\n\n\n\n  \n    \n      Explanation of helper function\n    \n    \n    \n      Element\n      Description\n    \n  \n  \n    prompt\nUser query send to OpenAI\n    messages\nWhen a user sends a query in plain text,  It has to be converted into list format which is understood by OpenAI. Every prompt has to be converted in this format\n    ChatCompletion Function\nFunction which is used to communicate to OpenAI\n    model\nThe name of model which a developer wants to interact It can be gpt 3.5 turbo, gpt 4 etc\n    temperature\nTemperature sets the randomness of the response. It is set to 0, the model is too deterministic and accurate. Use this option when accuracy is priority for e.g. code generation\n    response\nModel returns output as response object which  contains list of choices."
  },
  {
    "objectID": "2_chapter.html#understanding-the-response-object",
    "href": "2_chapter.html#understanding-the-response-object",
    "title": "2 Structure of API function",
    "section": "Understanding the response object",
    "text": "Understanding the response object\nIn the previous, section we saw the elements of helper function. When we call OpenAI ChatCompletion, we get their response as response object. Lets see the components of response.\nWe‚Äôll modify the helper function, where we‚Äôll see the response object directly to calling function.\n# Modified helper function\ndef get_completion(prompt):\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    response = openai.ChatCompletion.create(\n        model=\"gpt-3.5-turbo\",\n        messages=messages,\n        temperature=0.1, \n    )\n    return response\nprompt = \"Who discovered the laws of motion\"\nresponse = get_completion(prompt)\nprint(response)\nOutput:\n{   \n    \"id\": \"chatcmpl-8FPlpp8IMyWHneFYuXZQqKkKGK461\",   \n    \"object\": \"chat.completion\",   \n    \"created\": 1698684673,   \n    \"model\": \"gpt-3.5-turbo-0613\",   \n    \"choices\": [     \n      {       \n        \"index\": 0,       \n        \"message\": {         \n          \"role\": \"assistant\",\n          \"content\": \"The laws of motion were discovered by Sir Isaac Newton.\"       \n          },       \n          \"finish_reason\": \"stop\"     \n      }   \n    ],   \n    \"usage\": {     \n      \"prompt_tokens\": 13,     \n      \"completion_tokens\": 1,     \n      \"total_tokens\": 24   \n    } \n} \nAs, you can see above, the output of OpenAI ChatCompletion is a json object. Few keys are self explanatory, we can skip those and understand others by breaking into small parts.\n\nChoices\nChatCompletion.create function from OpenAI returns a response object like above.. In order to understand better, we‚Äôll break it and see output step wise.\nresponse.choices\nOutput:\n[&lt;OpenAIObject at 0x15932c6f950&gt; JSON: {    \n  \"index\": 0,    \n  \"message\": {      \n    \"role\": \"assistant\",      \n    \"content\": \"The laws of motion were discovered by Sir Isaac Newton.\"    \n    },    \n    \"finish_reason\": \"stop\"  \n  }]\nThis command will extract the choices from response which is a list of JSON. This list has only elements with JSON format. It has three keys index, message and finish_reason.\nresponse.choices[0]\n&lt;OpenAIObject at 0x22ea8fcfc50&gt; JSON: {   \n  \"index\": 0,   \n  \"message\": {     \n    \"role\": \"assistant\",     \n    \"content\": \"The laws of motion were discovered by Sir Isaac Newton.\"   \n  },   \n  \"finish_reason\": \"stop\" \n}\nSince, response.choices is a list with one element, this statement below üëáüèæ fetch the the first element from the list which is a json.\nresponse.choices[0].message\nOutput:\n&lt;OpenAIObject at 0x15932c6f9b0&gt; JSON: {   \n  \"role\": \"assistant\",   \n  \"content\": \"The laws of motion were discovered by Sir Isaac Newton.\" \n}\nThe message json has two elements, role and content which we generally use while bulding AI applications.\nFinally, we‚Äôll use this statement to fetch the response from OpenAI ChatCompletion.\nresponse.choices[0].message[\"content\"]\nOutput:\n'The laws of motion were discovered by Sir Isaac Newton.'\n\n\nGet Usage data\nMany times, there are requirement from business to keep track of total token usages. We can use the same response object to fetch token.\nIf you see the content of response, üëáüèæüëáüèæ, it has another key usage.\n{   \n    \"id\": \"chatcmpl-8FPlpp8IMyWHneFYuXZQqKkKGK461\",   \n    \"object\": \"chat.completion\",   \n    \"created\": 1698684673,   \n    \"model\": \"gpt-3.5-turbo-0613\",   \n    \"choices\": [     \n      {       \n        \"index\": 0,       \n        \"message\": {         \n          \"role\": \"assistant\",\n          \"content\": \"The laws of motion were discovered by Sir Isaac Newton.\"       \n          },       \n          \"finish_reason\": \"stop\"     \n      }   \n    ],   \n    \"usage\": {     \n      \"prompt_tokens\": 13,     \n      \"completion_tokens\": 1,     \n      \"total_tokens\": 24   \n    } \n} \nWe can extract usage using.\nresponse.usage\n&lt;OpenAIObject at 0x22ea8fcf950&gt; JSON: {\n  \"prompt_tokens\": 13,\n  \"completion_tokens\": 11,\n  \"total_tokens\": 24\n}\nIt has three keys prompt_tokens, completion_tokens, total_tokens.\nTo track the use of tokens, you can use\nresponse.usage[\"total_tokens\"]\n24"
  },
  {
    "objectID": "2_chapter.html#summary",
    "href": "2_chapter.html#summary",
    "title": "2 Structure of API function",
    "section": "Summary",
    "text": "Summary\nIn this chapter, we discussed the structure of helper function we created and OpenAI‚Äôs ChatCompletion."
  },
  {
    "objectID": "3_Chapter.html#structure-of-conversation",
    "href": "3_Chapter.html#structure-of-conversation",
    "title": "3 System Message",
    "section": "Structure of conversation",
    "text": "Structure of conversation\nTill now we saw how we send a single message inside OpenAI ChatCompletion to get response.\nmessages = [{\"role\": \"user\", \"content\": prompt}] \nBut in actual scenario, OpenAI ChatCompletion function use a conversation (or messages). This conversation is a list of individual objects, where each object has a role and content.\nHere is a sample conversation\nmessages = [\n  {\n    \"role\" : \"system\", \n    \"content\" : \"You are an expert in English who corrects any error in a sentence\"\n  },\n  {\n    \"role\" : \"user\",\n    \"content\" : \"Correct this 'I want eating apple red.\"\n  },\n  {\n    \"role\": \"assistant\",\n    \"content\": \"I want to eat a red apple.\"\n  }\n]\nA message can take 3 roles\n\nsystem\nuser\nassistant\n\nsystem message set the behavior of assistant. IT is added at the beginning of conversation to set the tone and may be restrict model to have in a certain way. A user message is followed after system message, it represent the actual question to be asked by user. When we send conversation with system and user message, ChatCompletion function respond using the role assistant.\nHere is the sample example,\nimport openai\nimport os\n\n# openai.api_key  = \"api key\"\nopenai.api_key  = os.getenv('OPENAI_API_KEY')\n\n\nmessages = [\n  {\n    \"role\" : \"system\", \n    \"content\" : \"You are an expert in English who corrects any error in a sentence\"\n  },\n  {\n    \"role\" : \"user\",\n    \"content\" : \"Correct this 'I want eating apple red.\"\n  }\n]\n\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",\n    messages=messages,\n    temperature=0.1, \n)\n\nresponse.choices[0].message\noutput\n&lt;OpenAIObject at 0x1e33f44f830&gt; JSON: {\n  \"role\": \"assistant\",\n  \"content\": \"I want to eat a red apple.\"\n}\nWe can use our standard format üëáüèæ if we want to see the content only.\nresponse.choices[0].message[\"content\"]\n'I want to eat a red apple.'"
  },
  {
    "objectID": "3_Chapter.html#a-sample-conversation",
    "href": "3_Chapter.html#a-sample-conversation",
    "title": "3 System Message",
    "section": "A sample conversation",
    "text": "A sample conversation\nNow we‚Äôll built a simple conversation to ask question to our own document like pdf or word file. I‚Äôll use a word file which contains text extracted from high school book.\nThe below code üëáüèæ will extract text from word document\n# !pip install python-docx # library to read word document\nimport docx\n\nfile_path = \"reference_text\\\\NCERT_Text.docx\"\ndoc = docx.Document(file_path)\ntext = \"\"\nfor paragraph in doc.paragraphs:\n    text += paragraph.text\nWe‚Äôll store our question which is based on text provided into four variables.\nquestion1 = \"Name the two temples the author visited in Kathmandu\"\nquestion2 = \"The writer says, ‚ÄúAll this I wash down with Coca Cola.‚Äù What does ‚Äòall this‚Äô refer to?\"\nquestion3 = \"What does Vikram Seth compare to the quills of a porcupine?\"\nquestion4 = \"Name five kinds of flutes.\"\nNow, we‚Äôll define the system prompt üëáüèæ.\nsystem_prompt = \"\"\"\nYou have excellent knowledge on English. When provided a text you can answer any question related to that text.\nYou always response in polite and simple language.\n\"\"\"\nHere we are giving background context to the model and also defining the tone which model has to use. Now we have to define the user message, that will go into model\n\nConversation 1\nLet‚Äôs see the response of first question .\nuser_prompt = f\"\"\"\nBased on below text delimited by three backticks ```. Answer the question which is delimited by \"###\".\n```\n{text}\n```\n\n###\n{question1}\n###\n\"\"\"\nprint(user_prompt)\nHere, we are giving clear instructions, by clearly defining the delimiter. It will make things simpler for model.\nconversation1 = [\n    {\"role\" : \"system\", \"content\" : system_prompt},\n    {\"role\" : \"user\", \"content\" : user_prompt}\n]\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",\n    messages=conversation1,\n    temperature=0.1, \n)\nresponse.choices[0].message[\"content\"]\nOutput:\nThe author visited two temples in Kathmandu. The first temple is called Pashupatinath and the second temple is called Baudhnath stupa.'\n\n\nConversation 2\nSince, it is a repetitive ask, lets create a function for this task.\ndef get_chat_completion(text, question):\n    user_prompt = f\"\"\"\n    Based on below text delimited by three backticks ```. Answer the question which is delimited by \"###\".\n    ```\n{text}\n```\n    \n    ###\n    {question}\n    ###\n    \"\"\"   \n    \n    conversation = [\n    {\"role\" : \"system\", \"content\" : system_prompt},\n    {\"role\" : \"user\", \"content\" : user_prompt}\n]\n    messages = [{\"role\": \"user\", \"content\": user_prompt}]\n    response = openai.ChatCompletion.create(\n        model=\"gpt-3.5-turbo\",\n        messages=conversation,\n        temperature=0.1, \n    )\n    return response.choices[0].message[\"content\"]\nresponse = get_chat_completion(text, question2)\nprint(response)\nOutput:\nThe phrase 'all this' refers to the things that the writer indulged in, such as buying a bar of marzipan, a corn-on-the-cob, love story comics, and even a Reader's Digest.\nIn this way, we can start building a solution using OpenAI API."
  },
  {
    "objectID": "3_Chapter.html#summary",
    "href": "3_Chapter.html#summary",
    "title": "3 System Message",
    "section": "Summary",
    "text": "Summary\nIn the next Chapter , we‚Äôll create a chat application using Streamlit."
  },
  {
    "objectID": "4_Chapter.html",
    "href": "4_Chapter.html",
    "title": "4 Chat with your own data",
    "section": "",
    "text": "In this chapter, we will create a solution using Streamlit which will Chat with the pdf document in your directory.\nThe first step will be to create a directory name chatwithpdf with below structure.\n‚îú‚îÄ‚îÄ chatwithpdf\n‚îÇ   ‚îú‚îÄ‚îÄ main.py\n‚îÇ   ‚îú‚îÄ‚îÄ Who_Healthy diet.pdf\nmain.py will store the code to run the streamlit application. Here is the complete code required to run the appication. We‚Äôll break into small chunks to understand.\nimport openai\nimport streamlit as st\nimport os\nfrom PyPDF2 import PdfReader\n\nst.title(\"Chatwith your data\")\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")\n\n\nreader = PdfReader(\"Who_Healthy diet.pdf\")\ncorpus = \"\"\nfor page in reader.pages:\n    corpus = corpus + \"\\n\" + page.extract_text()\n\nsystem_prompt = f\"\"\"\nYou have excellent knowledge on English. who can answer any question related to below text delimited by ```.\nYou always response in polite and simple language.\n\n```\n{corpus}\n```\n\"\"\"\n\nif \"messages\" not in st.session_state:\n    st.session_state.messages = []\n    st.session_state.messages.append({\"role\": \"system\", \"content\": system_prompt})\n\nfor message in st.session_state.messages:\n    with st.chat_message(message[\"role\"]):\n        if (message[\"role\"] != \"system\"):\n            st.markdown(message[\"content\"])\n\n\n\nif prompt := st.chat_input(\"How can I help you?\"):\n    \n    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n    with st.chat_message(\"user\"):\n        st.markdown(prompt)\n        response = openai.ChatCompletion.create(\n            model=\"gpt-3.5-turbo\",\n            messages=st.session_state.messages,\n            temperature=0.1, \n        ) \n        response_message = response.choices[0].message[\"content\"]\n        response_role = response.choices[0].message[\"role\"]\n        \n\n    with st.chat_message(\"assistant\"):\n        st.markdown(response_message)\n    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response_message})\nAfter we have loaded necessary libraries and openai key. The first step will be to load the content of pdf. A common powerful library for reading pdf is PyPDF2.\nreader = PdfReader(\"Who_Healthy diet.pdf\")\ntext = \"\"\nfor page in reader.pages:\n    text = text + \"\\n\" + page.extract_text()\nThe above statements, will iterate through all pages of pdf and load the content into a string variable text. We will use this text variable into system message.\nsystem_prompt = f\"\"\"\nYou have excellent knowledge on English. who can answer any question related to below text delimited by ```.\nYou always response in polite and simple language.\n\n```\n{text}\n```\n\"\"\"\nHere we define, our system message.\nPlease note, we are sending our text into system prompt, and not user prompt. FInally we have the streamlit specific code which we use to create chat application.\n\nif \"messages\" not in st.session_state:\n    st.session_state.messages = []\n    st.session_state.messages.append({\"role\": \"system\", \"content\": system_prompt})\n\nfor message in st.session_state.messages:\n    with st.chat_message(message[\"role\"]):\n        if (message[\"role\"] != \"system\"):\n            st.markdown(message[\"content\"])\n\n\n\nif prompt := st.chat_input(\"How can I help you?\"):\n    \n    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n    with st.chat_message(\"user\"):\n        st.markdown(prompt)\n        response = openai.ChatCompletion.create(\n            model=\"gpt-3.5-turbo\",\n            messages=st.session_state.messages,\n            temperature=0.1, \n        ) \n        response_message = response.choices[0].message[\"content\"]\n        response_role = response.choices[0].message[\"role\"]\n        \n\n    with st.chat_message(\"assistant\"):\n        st.markdown(response_message)\n    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response_message})\nIn order to run this application, you have to go the folder containing main.py and execute\nstreamlit run main.py .\nIn this way, you can create a simple running chat application which can run on your own data."
  }
]